{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**LOGISTICS REGRESSION**"
      ],
      "metadata": {
        "id": "-TW-9Sm3Ub_5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**THEORITICAL QUESTIONS**"
      ],
      "metadata": {
        "id": "ZSX0xOVLUb6K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. What is Logistic Regression, and how does it differ from Linear Regression ?**\n",
        "\n",
        "- **Logistic Regression** is a supervised learning algorithm primarily used for **classification problems**, especially when the target variable is categorical with two classes (binary classification). It estimates the probability that a given input belongs to a particular class by modeling the relationship between the input features and the log-odds of the event occurring.\n",
        "\n",
        "- In contrast, **Linear Regression** is used for **regression problems**, where the target variable is continuous. It models the relationship between inputs and a continuous output by fitting a straight line (or hyperplane) through the data points.\n",
        "\n",
        "- **Key differences :**\n",
        "\n",
        " * **Output :**\n",
        "\n",
        "   * Linear Regression predicts continuous numeric values (like price, height).\n",
        "   \n",
        "   * Logistic Regression predicts the probability of class membership, which is bounded between 0 and 1.\n",
        "\n",
        " * **Function form :**\n",
        "\n",
        "   * Linear Regression uses a linear equation $y = \\beta_0 + \\beta_1 x_1 + \\cdots + \\beta_n x_n$.\n",
        "   \n",
        "   * Logistic Regression applies a **sigmoid function** to this linear combination to map predictions to probabilities.\n",
        "\n",
        " * **Loss function :**\n",
        "\n",
        "   * Linear Regression uses **Mean Squared Error** to minimize prediction errors.\n",
        "\n",
        "   * Logistic Regression uses **Cross-Entropy Loss (Log Loss)**, which measures the dissimilarity between predicted probabilities and true labels.\n",
        "\n",
        " * **Application :**\n",
        "\n",
        "   * Linear Regression for prediction and forecasting continuous values.\n",
        "  \n",
        "   * Logistic Regression for classification, such as spam detection, disease diagnosis, or customer churn prediction.\n",
        "\n",
        "**2. What is the mathematical equation of Logistic Regression ?**\n",
        "\n",
        "- Logistic regression models the probability that the dependent variable $y$ belongs to the positive class $(y=1)$, given the input features $\\mathbf{x}$.\n",
        "\n",
        "- **Step 1 : Compute the linear combination of inputs**\n",
        "\n",
        "$$\n",
        "z = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\cdots + \\beta_n x_n = \\mathbf{\\beta}^T \\mathbf{x}\n",
        "$$\n",
        "\n",
        "where $\\beta_0$ is the intercept and $\\beta_i$ are the coefficients.\n",
        "\n",
        "- **Step 2 : Apply the sigmoid (logistic) function to convert $z$ into a probability**\n",
        "\n",
        "$$\n",
        "P(y=1 | \\mathbf{x}) = \\sigma(z) = \\frac{1}{1 + e^{-z}} = \\frac{1}{1 + e^{-(\\beta_0 + \\sum_{i=1}^n \\beta_i x_i)}}\n",
        "$$\n",
        "\n",
        "The sigmoid function squashes any real number into the range (0, 1), making it interpretable as a probability.\n",
        "\n",
        "**3. Why do we use the Sigmoid function in Logistic Regression ?**\n",
        "\n",
        "- The **sigmoid function** is used because :\n",
        "\n",
        " * It **maps the linear output $z$** (which ranges from $-\\infty$ to $+\\infty$) to a **probability between 0 and 1**, enabling interpretation as the likelihood of class membership.\n",
        "\n",
        " * It produces an **S-shaped curve**, smoothly transitioning between values close to 0 for large negative inputs, and close to 1 for large positive inputs.\n",
        "\n",
        " * It is **differentiable everywhere**, which is crucial for optimization algorithms like gradient descent to calculate gradients and update model parameters.\n",
        "\n",
        " * Without the sigmoid, the model would predict values outside the \\[0, 1] interval, which are not valid probabilities.\n",
        "\n",
        "**4. What is the cost function of Logistic Regression ?**\n",
        "\n",
        "- The cost function measures how well the logistic regression model fits the training data by comparing predicted probabilities to actual class labels. It is called **Cross-Entropy Loss** or **Log Loss**, defined as :\n",
        "\n",
        "$$\n",
        "J(\\beta) = -\\frac{1}{m} \\sum_{i=1}^m \\left[ y^{(i)} \\log \\hat{y}^{(i)} + (1 - y^{(i)}) \\log (1 - \\hat{y}^{(i)}) \\right]\n",
        "$$\n",
        "\n",
        "- where :\n",
        "\n",
        " * $m$ is the number of training samples.\n",
        "\n",
        " * $y^{(i)} \\in \\{0, 1\\}$ is the true label.\n",
        "\n",
        " * $\\hat{y}^{(i)} = P(y=1 | \\mathbf{x}^{(i)})$ is the predicted probability.\n",
        "\n",
        "- **Intuition :**\n",
        "\n",
        " * When $y=1$, the first term $-\\log(\\hat{y})$ penalizes low predicted probabilities for the positive class.\n",
        "\n",
        " * When $y=0$, the second term $-\\log(1 - \\hat{y})$ penalizes high predicted probabilities for the negative class.\n",
        "\n",
        " * The loss is minimized when predicted probabilities match actual labels closely.\n",
        "\n",
        "**5. What is Regularization in Logistic Regression? Why is it needed ?**\n",
        "\n",
        "- **Regularization** is a technique that adds a penalty term to the cost function to discourage overly complex models and reduce overfitting. Overfitting happens when a model captures noise or random fluctuations in the training data rather than the underlying pattern, leading to poor generalization on new data.\n",
        "\n",
        "- **Why is regularization needed ?**\n",
        "\n",
        " * **Avoids overfitting :** By penalizing large coefficients, the model becomes simpler and more generalizable.\n",
        "\n",
        " * **Handles multicollinearity :** When predictors are highly correlated, regularization stabilizes coefficient estimates.\n",
        "\n",
        " * **Feature selection :** Certain types of regularization can shrink some coefficients exactly to zero, effectively selecting a subset of features.\n",
        "\n",
        "**6. Explain the difference between Lasso, Ridge, and Elastic Net regression.**\n",
        "\n",
        "* **Lasso (L1) Regularization:**\n",
        "   \n",
        "   - Adds a penalty equal to the **absolute values** of the coefficients :\n",
        "\n",
        "  $$\n",
        "  \\lambda \\sum_{i=1}^n |\\beta_i|\n",
        "  $$\n",
        "\n",
        "  Lasso can shrink some coefficients exactly to zero, performing **feature selection** and producing sparse models.\n",
        "\n",
        "* **Ridge (L2) Regularization:**\n",
        "   \n",
        "   - Adds a penalty equal to the **square of the coefficients :**\n",
        "\n",
        "  $$\n",
        "  \\lambda \\sum_{i=1}^n \\beta_i^2\n",
        "  $$\n",
        "\n",
        "  Ridge shrinks coefficients but does not set them exactly to zero. It’s good for reducing model complexity while keeping all features.\n",
        "\n",
        "* **Elastic Net Regularization :**\n",
        "   \n",
        "   - Combines L1 and L2 penalties :\n",
        "\n",
        "  $$\n",
        "  \\lambda \\left( \\alpha \\sum_{i=1}^n |\\beta_i| + (1-\\alpha) \\sum_{i=1}^n \\beta_i^2 \\right)\n",
        "  $$\n",
        "\n",
        "  Elastic Net balances between sparsity (like Lasso) and coefficient shrinkage (like Ridge), especially useful when predictors are highly correlated.\n",
        "\n",
        "**7. When should we use Elastic Net instead of Lasso or Ridge ?**\n",
        "\n",
        "- Use **Elastic Net** when :\n",
        "\n",
        " * Our data has **many correlated features**. Lasso may arbitrarily pick one feature and ignore others, while Elastic Net keeps groups of correlated features.\n",
        "\n",
        " * Pure Lasso leads to **unstable feature selection**.\n",
        "\n",
        " * We want a **balance** between feature selection and coefficient shrinkage.\n",
        "\n",
        " * The number of features is larger than the number of observations (high-dimensional data).\n",
        "\n",
        "**8. What is the impact of the regularization parameter ($\\lambda$) in Logistic Regression ?**\n",
        "\n",
        "- The parameter $\\lambda$ controls the **strength of the regularization penalty** :\n",
        "\n",
        " * **Large $\\lambda$ :** Strong regularization; coefficients shrink more aggressively towards zero; can cause underfitting if too large.\n",
        "\n",
        " * **Small $\\lambda$ :** Weak regularization; model may overfit training data; coefficients remain large.\n",
        "\n",
        "- Selecting the optimal $\\lambda$ balances the bias-variance tradeoff and is commonly done via **cross-validation**.\n",
        "\n",
        "**9. What are the key assumptions of Logistic Regression ?**\n",
        "\n",
        "* **Binary or categorical dependent variable :** The target variable is categorical.\n",
        "\n",
        "* **Linear relationship :** The log-odds of the outcome are linearly related to the predictor variables.\n",
        "\n",
        "* **Independence of observations :** Data samples are independent.\n",
        "\n",
        "* **No multicollinearity :** Predictors should not be highly correlated.\n",
        "\n",
        "* **Large sample size :** Logistic regression requires sufficient data to estimate parameters reliably.\n",
        "\n",
        "* **Absence of outliers :** Extreme outliers can distort the model.\n",
        "\n",
        "**10. What are some alternatives to Logistic Regression for classification tasks ?**\n",
        "\n",
        "* **Decision Trees :** Non-linear, interpretable models that split data based on feature thresholds.\n",
        "\n",
        "* **Random Forests :** Ensembles of decision trees for improved accuracy and robustness.\n",
        "\n",
        "* **Support Vector Machines (SVM) :** Finds hyperplanes maximizing class separation, effective in high-dimensional space.\n",
        "\n",
        "* **k-Nearest Neighbors (k-NN) :** Classifies based on the majority class of nearest neighbors.\n",
        "\n",
        "* **Naive Bayes :** Probabilistic classifier assuming feature independence.\n",
        "\n",
        "* **Neural Networks :** Highly flexible models for complex, non-linear relationships.\n",
        "\n",
        "* **Gradient Boosting Machines :** Powerful ensemble methods like XGBoost, LightGBM.\n",
        "\n",
        "**11. What are Classification Evaluation Metrics ?**\n",
        "\n",
        "* **Accuracy :** Proportion of correctly predicted instances.\n",
        "\n",
        "* **Precision :** Of the predicted positives, how many are true positives.\n",
        "\n",
        "* **Recall (Sensitivity) :** Of the actual positives, how many were identified.\n",
        "\n",
        "* **F1 Score :** Harmonic mean of precision and recall, useful for imbalanced datasets.\n",
        "\n",
        "* **Confusion Matrix :** Displays counts of TP, TN, FP, FN.\n",
        "\n",
        "* **ROC Curve :** Graph of True Positive Rate vs. False Positive Rate at various thresholds.\n",
        "\n",
        "* **AUC (Area Under the ROC Curve) :** Measures overall model discrimination capability.\n",
        "\n",
        "**12. How does class imbalance affect Logistic Regression ?**\n",
        "\n",
        "- Class imbalance occurs when one class significantly outnumbers the other(s). Effects include :\n",
        "\n",
        " * Model biases towards majority class.\n",
        "\n",
        " * Poor predictive performance on minority class.\n",
        "\n",
        " * Accuracy becomes misleading as the model may always predict the majority class.\n",
        "\n",
        "- **Solutions :**\n",
        "\n",
        " * Use evaluation metrics like precision, recall, and F1 score instead of accuracy.\n",
        "\n",
        " * Resample data (oversample minority, undersample majority).\n",
        "\n",
        " * Apply **class weights** to penalize misclassification of minority class more heavily.\n",
        "\n",
        "**13. What is Hyperparameter Tuning in Logistic Regression ?**\n",
        "\n",
        "- Hyperparameter tuning is the process of selecting the best model parameters, such as :\n",
        "\n",
        " * Regularization strength ($\\lambda$)\n",
        "\n",
        " * Type of regularization (L1, L2, Elastic Net)\n",
        "\n",
        " * Solver choice\n",
        "\n",
        "- Tuning is typically done through **grid search** or **random search** combined with **cross-validation** to maximize generalization performance.\n",
        "\n",
        "**14. What are different solvers in Logistic Regression? Which one should be used ?**\n",
        "\n",
        "- Solvers are algorithms that optimize the logistic regression cost function :\n",
        "\n",
        " * **liblinear :** Good for small datasets; supports L1 and L2 penalties.\n",
        "\n",
        " * **newton-cg :** Uses Newton’s method; efficient with L2.\n",
        "\n",
        " * **lbfgs :** Quasi-Newton method; fast for large datasets; supports L2.\n",
        "\n",
        " * **sag (Stochastic Average Gradient) :** Efficient for very large datasets with L2.\n",
        "\n",
        " * **saga :** Extension of sag; supports L1, L2, and Elastic Net.\n",
        "\n",
        "- **Choice depends on dataset size and penalty :**\n",
        "\n",
        " * For small datasets and L1 penalty : **liblinear**.\n",
        "\n",
        " * For large datasets and L2 : **lbfgs** or **sag/saga**.\n",
        "\n",
        " * For Elastic Net : **saga**.\n",
        "\n",
        "**15. How is Logistic Regression extended for multiclass classification ?**\n",
        "\n",
        "* **One-vs-Rest (OvR) :** Train a binary classifier per class, treating it as positive vs all others negative. Predict class with highest probability.\n",
        "\n",
        "* **Softmax Regression (Multinomial Logistic Regression) :** Directly models all classes simultaneously using the softmax function, which generalizes sigmoid to multiple classes.\n",
        "\n",
        "**16. What are the advantages and disadvantages of Logistic Regression ?**\n",
        "\n",
        "- **Advantages :**\n",
        "\n",
        " * Simple and easy to implement.\n",
        "\n",
        " * Outputs interpretable probabilities.\n",
        "\n",
        " * Computationally efficient.\n",
        "\n",
        " * Works well on linearly separable data.\n",
        "\n",
        " * Well-understood theory and diagnostics.\n",
        "\n",
        "- **Disadvantages :**\n",
        "\n",
        " * Assumes linear relationship between features and log-odds.\n",
        "\n",
        " * Poor performance on complex, non-linear problems.\n",
        "\n",
        " * Sensitive to outliers.\n",
        "\n",
        " * Requires large sample size.\n",
        "\n",
        " * Can struggle with multicollinearity.\n",
        "\n",
        "**17. How do you interpret the coefficients in Logistic Regression ?**\n",
        "\n",
        "* Coefficients represent the **change in the log-odds** of the outcome for a one-unit increase in the predictor, holding other variables constant.\n",
        "\n",
        "* Exponentiating the coefficient $e^{\\beta_i}$ gives the **odds ratio**, indicating how the odds of the positive class change.\n",
        "\n",
        "  * $e^{\\beta_i} > 1$ : Predictor increases odds.\n",
        "\n",
        "  * $e^{\\beta_i} < 1$ : Predictor decreases odds.\n",
        "\n",
        "* Helps understand feature importance and directionality.\n",
        "\n",
        "**18. What is the decision boundary in Logistic Regression ?**\n",
        "\n",
        "- The decision boundary is the **set of points where the model predicts a 50% probability**, i.e.,\n",
        "\n",
        "$$\n",
        "P(y=1|\\mathbf{x}) = 0.5\n",
        "$$\n",
        "\n",
        "Since the sigmoid function outputs 0.5 when $z = 0$,\n",
        "\n",
        "$$\n",
        "\\beta_0 + \\beta_1 x_1 + \\cdots + \\beta_n x_n = 0\n",
        "$$\n",
        "\n",
        "This boundary separates predicted classes and is **linear in the feature space**.\n",
        "\n",
        "**19. How can you handle non-linearity in Logistic Regression ?**\n",
        "\n",
        "* **Feature Engineering :** Create polynomial or interaction features to capture non-linear relationships.\n",
        "\n",
        "* **Use basis expansions :** Splines, piecewise functions.\n",
        "\n",
        "* **Kernel methods :** Though not standard in logistic regression, kernel logistic regression extends it non-linearly.\n",
        "\n",
        "* **Use non-linear classifiers :** Like decision trees, SVMs with kernels, or neural networks if non-linearity is too complex.\n",
        "\n",
        "**20. How do you check the goodness-of-fit of a Logistic Regression model ?**\n",
        "\n",
        "* **Likelihood Ratio Test :** Compares fitted model to a null model.\n",
        "\n",
        "* **Pseudo R-squared metrics :** Like McFadden’s $R^2$, indicating explanatory power.\n",
        "\n",
        "* **Hosmer-Lemeshow Test :** Tests if predicted probabilities match observed outcomes across groups.\n",
        "\n",
        "* **Confusion Matrix and classification metrics :** Assess accuracy and error.\n",
        "\n",
        "* **ROC curve and AUC :** Evaluate discrimination.\n",
        "\n",
        "* **Residual Analysis :** Examine deviance or Pearson residuals for model fit."
      ],
      "metadata": {
        "id": "ZvER6wZWU0fo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PRACTICAL QUESTIONS**"
      ],
      "metadata": {
        "id": "Yu4E9-ttUwsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Required Libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris, load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score, RandomizedSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
        "from sklearn.metrics import classification_report, cohen_kappa_score, matthews_corrcoef, roc_curve, precision_recall_curve\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n"
      ],
      "metadata": {
        "id": "0WfbRCQnPsUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Write a Python program that loads a dataset, splits it into training and testing sets, applies Logistic\n",
        "Regression, and prints the model accuracy.**"
      ],
      "metadata": {
        "id": "HcbrY7j0ciFo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7W2XNEeTQsu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c575c2db-9a3a-496c-dfa7-99bc894a65a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, model.predict(X_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.  Write a Python program to apply L1 regularization (Lasso) on a dataset using LogisticRegression(penalty='l1')\n",
        "and print the model accuracy.**"
      ],
      "metadata": {
        "id": "9T3EMH_WQXDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_l1 = LogisticRegression(penalty='l1', solver='liblinear', max_iter=200)\n",
        "model_l1.fit(X_train, y_train)\n",
        "print(\"L1 Accuracy:\", accuracy_score(y_test, model_l1.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEO82qdRQaBe",
        "outputId": "9d2b0080-1dca-48b1-d6a8-fc6d016f33be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L1 Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Write a Python program to train Logistic Regression with L2 regularization (Ridge) using\n",
        "LogisticRegression(penalty='l2'). Print model accuracy and coefficients.**"
      ],
      "metadata": {
        "id": "7XUM80-xQi7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_l2 = LogisticRegression(penalty='l2', solver='liblinear', max_iter=200)\n",
        "model_l2.fit(X_train, y_train)\n",
        "print(\"L2 Accuracy:\", accuracy_score(y_test, model_l2.predict(X_test)))\n",
        "print(\"Coefficients:\", model_l2.coef_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFZNRn3IQof-",
        "outputId": "024255b7-67d3-4038-f350-df5460a9c117"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L2 Accuracy: 0.9777777777777777\n",
            "Coefficients: [[ 0.36479402  1.35499766 -2.09628559 -0.92154751]\n",
            " [ 0.4808915  -1.58463288  0.3937527  -1.09224057]\n",
            " [-1.5286415  -1.43244729  2.3048277   2.08584535]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty='elasticnet').**"
      ],
      "metadata": {
        "id": "AyCV3zXBQuDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_elastic = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, max_iter=200)\n",
        "model_elastic.fit(X_train, y_train)\n",
        "print(\"Elastic Net Accuracy:\", accuracy_score(y_test, model_elastic.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFz3C5laQ_Pg",
        "outputId": "099b5a54-e3c0-437e-fbd6-096f381a2f3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elastic Net Accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Write a Python program to train a Logistic Regression model for multiclass classification using\n",
        "multi_class='ovr'.**"
      ],
      "metadata": {
        "id": "fxTRfhtzRPZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ovr = LogisticRegression(multi_class='ovr', solver='liblinear', max_iter=200)\n",
        "model_ovr.fit(X_train, y_train)\n",
        "print(\"OVR Accuracy:\", accuracy_score(y_test, model_ovr.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3h23Bi7RS_m",
        "outputId": "a65886bc-c427-470e-fa00-1a1360eaf6f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OVR Accuracy: 0.9777777777777777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic Regression. Print the best parameters and accuracy.**"
      ],
      "metadata": {
        "id": "CZwvnOCXRgsx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {'C': [0.1, 1, 10], 'penalty': ['l1', 'l2'], 'solver': ['liblinear']}\n",
        "grid = GridSearchCV(LogisticRegression(max_iter=200), params, cv=5)\n",
        "grid.fit(X_train, y_train)\n",
        "print(\"Best Params:\", grid.best_params_)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, grid.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PL2a3q17Rkwf",
        "outputId": "11ee61cb-5830-439b-f1c7-b88693933956"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Params: {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation. Print the\n",
        "average accuracy.**"
      ],
      "metadata": {
        "id": "IDW6CAy8RrLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv = StratifiedKFold(n_splits=5)\n",
        "scores = cross_val_score(LogisticRegression(max_iter=200), X, y, cv=cv)\n",
        "print(\"Stratified K-Fold Avg Accuracy:\", scores.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hKQh0jSRu5w",
        "outputId": "27b65d92-6c15-498b-aca0-b50d33544164"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stratified K-Fold Avg Accuracy: 0.9733333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. Write a Python program to load a dataset from a CSV file, apply Logistic Regression, and evaluate its\n",
        "accuracy.**"
      ],
      "metadata": {
        "id": "OBiVKWBhRzLw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace 'our_file.csv' with our actual file\n",
        "# df = pd.read_csv('our_file.csv')\n",
        "# For demo: iris again\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "model_csv = LogisticRegression(max_iter=200)\n",
        "model_csv.fit(X_train, y_train)\n",
        "print(\"CSV Data Accuracy:\", accuracy_score(y_test, model_csv.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tBqusbXTcNV",
        "outputId": "b8feb7ac-63ca-43aa-9b41-280d3c00311f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV Data Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9. Write a Python program to apply RandomizedSearchCV for tuning hyperparameters (C, penalty, solver) in\n",
        "Logistic Regression. Print the best parameters and accuracy.**"
      ],
      "metadata": {
        "id": "2HHvVMvZTnyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_dist = {'C': np.logspace(-3, 3, 10), 'penalty': ['l1', 'l2'], 'solver': ['liblinear', 'saga']}\n",
        "random_search = RandomizedSearchCV(LogisticRegression(max_iter=200), param_dist, n_iter=10, cv=3)\n",
        "random_search.fit(X_train, y_train)\n",
        "print(\"Best Params:\", random_search.best_params_)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, random_search.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yxvixlCeTp6m",
        "outputId": "2db16d91-5921-4339-a4da-f4d0b5637155"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Params: {'solver': 'saga', 'penalty': 'l2', 'C': np.float64(0.46415888336127775)}\n",
            "Accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10. Write a Python program to implement One-vs-One (OvO) Multiclass Logistic Regression and print accuracy.**"
      ],
      "metadata": {
        "id": "qz8PlemiTyD0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ovo_model = OneVsOneClassifier(LogisticRegression(max_iter=200))\n",
        "ovo_model.fit(X_train, y_train)\n",
        "print(\"OvO Accuracy:\", accuracy_score(y_test, ovo_model.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7jVfQNlT0ZY",
        "outputId": "eda4c6d4-ae1f-4524-8f31-f75aa38541da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OvO Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**11. Write a Python program to train a Logistic Regression model and visualize the confusion matrix for binary\n",
        "classification.**"
      ],
      "metadata": {
        "id": "9wTVHk8LU-kg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(confusion_matrix(y_test, model.predict(X_test)), annot=True)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "TF3ThZGOVJPi",
        "outputId": "20f648ca-c72d-4082-ca2f-ca6901b12872"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**12. Write a Python program to train a Logistic Regression model and evaluate its performance using Precision,\n",
        "Recall, and F1-Score.**"
      ],
      "metadata": {
        "id": "lQBs57lpU-hJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "print(\"Precision:\", precision_score(y_test, y_pred, average='macro'))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred, average='macro'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMH4d2XQVN_d",
        "outputId": "ca42eeaa-1a57-41f1-c2e1-fbbbafcb1ffb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**13. Write a Python program to train a Logistic Regression model on imbalanced data and apply class weights to\n",
        "improve model performance.**"
      ],
      "metadata": {
        "id": "LrVA7fGjU-d8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulating imbalance with binary classification\n",
        "X_bin = X[y != 2]\n",
        "y_bin = y[y != 2]\n",
        "model_weighted = LogisticRegression(class_weight='balanced')\n",
        "model_weighted.fit(X_bin, y_bin)\n",
        "print(\"Weighted Accuracy:\", accuracy_score(y_bin, model_weighted.predict(X_bin)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oo_eUvObVRv9",
        "outputId": "a740f2f5-2da6-4219-aadd-ded1bb58497a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weighted Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**14. Write a Python program to train Logistic Regression on the Titanic dataset, handle missing values, and\n",
        "evaluate performance.**"
      ],
      "metadata": {
        "id": "wFTXTR5jU-ap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df = pd.read_csv('titanic.csv')\n",
        "# df = df.fillna(df.mean(numeric_only=True))\n",
        "# X = df[['Age', 'Fare', 'Pclass']]; y = df['Survived']\n",
        "# model.fit(X, y)\n",
        "# print(\"Titanic Accuracy:\", accuracy_score(y, model.predict(X)))\n",
        "print(\"Placeholder for Titanic dataset processing.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuQIDdu5VYd6",
        "outputId": "b667916b-d694-4cc2-a9b4-00b0b1d8793f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Placeholder for Titanic dataset processing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**15. Write a Python program to apply feature scaling (Standardization) before training a Logistic Regression\n",
        "model. Evaluate its accuracy and compare results with and without scaling.**"
      ],
      "metadata": {
        "id": "KmaE3DEaU-XV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "model_scaled = LogisticRegression(max_iter=200)\n",
        "model_scaled.fit(X_scaled, y)\n",
        "print(\"Accuracy With Scaling:\", accuracy_score(y, model_scaled.predict(X_scaled)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mwr4dL2tVcHJ",
        "outputId": "2d249837-eb55-4b24-fce5-fa01cf6c42d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy With Scaling: 0.9733333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**16. Write a Python program to train Logistic Regression and evaluate its performance using ROC-AUC score.**"
      ],
      "metadata": {
        "id": "pWN3yALLU-UT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cancer = load_breast_cancer()\n",
        "X_c, y_c = cancer.data, cancer.target\n",
        "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X_c, y_c, test_size=0.3, random_state=42)\n",
        "model_roc = LogisticRegression(max_iter=200)\n",
        "model_roc.fit(X_train_c, y_train_c)\n",
        "probs = model_roc.predict_proba(X_test_c)[:,1]\n",
        "print(\"ROC AUC Score:\", roc_auc_score(y_test_c, probs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Lz7tJZxViDI",
        "outputId": "14e620b0-4191-4368-ce29-11d4d2d7b8ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC AUC Score: 0.9977954144620812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**17. Write a Python program to train Logistic Regression using a custom learning rate (C=0.5) and evaluate\n",
        "accuracy.**"
      ],
      "metadata": {
        "id": "4kllU9UfU-Q-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_c = LogisticRegression(C=0.5, max_iter=200)\n",
        "model_c.fit(X_train, y_train)\n",
        "print(\"C=0.5 Accuracy:\", accuracy_score(y_test, model_c.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLNov9mmVm74",
        "outputId": "2ad4ed12-4779-4b45-898b-77227f0849ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C=0.5 Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**18. Write a Python program to train Logistic Regression and identify important features based on model\n",
        "coefficients.**"
      ],
      "metadata": {
        "id": "M2qQtb68U-Ns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "importance = model.coef_[0]\n",
        "print(\"Feature Importances:\", importance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UhFC6wdVqld",
        "outputId": "66635073-f0a3-4cf5-99b4-a5b629fd8257"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importances: [-0.40538546  0.86892246 -2.2778749  -0.95680114]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**19.  Write a Python program to train Logistic Regression and evaluate its performance using Cohen’s Kappa\n",
        "Score.**"
      ],
      "metadata": {
        "id": "lItudrFYU-KE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Cohen's Kappa:\", cohen_kappa_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJogEmroVuY8",
        "outputId": "24f315f2-d6c6-4089-9069-55db903bb88b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cohen's Kappa: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**20.  Write a Python program to train Logistic Regression and visualize the Precision-Recall Curve for binary\n",
        "classification.**"
      ],
      "metadata": {
        "id": "EJP2IeVvU-HM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prec, rec, _ = precision_recall_curve(y_test_c, probs)\n",
        "plt.plot(rec, prec)\n",
        "plt.title(\"Precision-Recall Curve\")\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "1lWEhlRdV2Z4",
        "outputId": "bd842978-c376-4d53-ae5d-1ab1106a5f62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**21. Write a Python program to train Logistic Regression with different solvers (liblinear, saga, lbfgs) and compare their accuracy.**"
      ],
      "metadata": {
        "id": "QcdMjCSaU-EI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for solver in ['liblinear', 'saga', 'lbfgs']:\n",
        "    model_solver = LogisticRegression(solver=solver, max_iter=200)\n",
        "    model_solver.fit(X_train, y_train)\n",
        "    acc = accuracy_score(y_test, model_solver.predict(X_test))\n",
        "    print(f\"Solver: {solver}, Accuracy: {acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uTwshcJV7A_",
        "outputId": "8e61a1a3-5a45-4d7b-e81e-9fb9c44ed60b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solver: liblinear, Accuracy: 0.9777777777777777\n",
            "Solver: saga, Accuracy: 1.0\n",
            "Solver: lbfgs, Accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**22. Write a Python program to train Logistic Regression and evaluate its performance using Matthews\n",
        "Correlation Coefficient (MCC).**"
      ],
      "metadata": {
        "id": "aZPUn9csU-Ai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"MCC:\", matthews_corrcoef(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHNuZjgcV_e4",
        "outputId": "885031a5-97c0-4291-a1d6-ae7eb1b4fce7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MCC: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**23. Write a Python program to train Logistic Regression on both raw and standardized data. Compare their\n",
        "accuracy to see the impact of feature scaling.**"
      ],
      "metadata": {
        "id": "bvlc3wX2U99B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_model = LogisticRegression(max_iter=200).fit(X, y)\n",
        "std_model = LogisticRegression(max_iter=200).fit(StandardScaler().fit_transform(X), y)\n",
        "print(\"Raw Accuracy:\", accuracy_score(y, raw_model.predict(X)))\n",
        "print(\"Scaled Accuracy:\", accuracy_score(y, std_model.predict(StandardScaler().fit_transform(X))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYF2N1XMWDeg",
        "outputId": "61e70c48-da2b-420a-99c6-cb6b7977dce9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw Accuracy: 0.9733333333333334\n",
            "Scaled Accuracy: 0.9733333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**24. Write a Python program to train Logistic Regression and find the optimal C (regularization strength) using cross-validation.**"
      ],
      "metadata": {
        "id": "wJEak12RU95c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Cs = [0.01, 0.1, 1, 10]\n",
        "scores = [cross_val_score(LogisticRegression(C=c, max_iter=200), X, y, cv=5).mean() for c in Cs]\n",
        "best_C= Cs[np.argmax(scores)]\n",
        "print(\"Best C:\", best_C)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9EX3DEVWI1L",
        "outputId": "1269ba2a-198a-47a0-a3e8-c81c48111222"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best C: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**25. Write a Python program to train Logistic Regression, save the trained model using joblib, and load it again to make predictions.**"
      ],
      "metadata": {
        "id": "cHNw9MpiU91w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(model, \"logreg_model.joblib\")\n",
        "loaded_model = joblib.load(\"logreg_model.joblib\")\n",
        "print(\"Loaded Model Accuracy:\", accuracy_score(y_test, loaded_model.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YU45BDsrWPIz",
        "outputId": "e3e9ea66-2de8-4f4d-8ff2-bcc20bc41647"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded Model Accuracy: 1.0\n"
          ]
        }
      ]
    }
  ]
}